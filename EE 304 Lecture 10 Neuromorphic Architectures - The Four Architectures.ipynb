{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE 304 - Neuromorphics: Brains in Silicon\n",
    "\n",
    "\n",
    "##  Neuromorphic Architectures\n",
    "\n",
    "The story thus far: We have implemented two of a neuron's elements:\n",
    "\n",
    "- An exponentially decaying synapse\n",
    "    - a log-domain lowpass filter\n",
    "- A quadratic integrate-and-fire soma\n",
    "    - a log-domain lowpass filter plus a current mirror\n",
    "    \n",
    "####  Outline for this lecture\n",
    "\n",
    "We will study four distincly different architectures \n",
    "\n",
    "When we implement networks of spiking neurons in silicon, we may choose:\n",
    "\n",
    "- to <b> dedicate </b> each hardware element to a single neuronal element \n",
    "- or to <b> share </b> it among several neural elements\n",
    "\n",
    "For instance:\n",
    "\n",
    "- We could carry a silicon neuron's spikes on a metal wire dedicated to it\n",
    "- Or we could transmit its spike train on a bus\n",
    "- Along with spike trains of other silicon neurons\n",
    "- This cuts the number of wires from $N$ to $\\log_2(N)$\n",
    "\n",
    "Sharing axons, synapses, and dendrites, reduces hardware requirements\n",
    "\n",
    "- The savings compound\n",
    "- Resulting in architetures with distincly different scaling properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Four Neuronal Elements \n",
    "\n",
    "<img src=\"files/lecture10/TwoNeuronNetwork.png\" width=\"720\">\n",
    "\n",
    "In all, a neuron has four elements:\n",
    "\n",
    "- <b>Axon</b>: Communicates its spikes to other neurons\n",
    "- <b>Synapse</b>: Coverts a spike to a graded potential\n",
    "- <b>Dendrite</b>: Summates these graded potentials \n",
    "- <b>Soma</b>: Converts these summated graded potentials to a spike train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Four Architectures \n",
    "\n",
    "As we map a spiking neural network's neuronal elements onto our silicon chip's hardware elements, we must choose whether to dedicate or share them.\n",
    "\n",
    "We may make choices, progressively, for each of the four types of neuronal elements.\n",
    "\n",
    "This leads to four distinct architectures:\n",
    "\n",
    "- <b>Fully-Dedicated</b>: Each hardware element is dedicated to a single neuronal element\n",
    "- <b>Shared-Axon</b>: $\\log_2(N)$ metal wires are shared by $N$ axons \n",
    "- <b>Shared-Synapse</b>: A single lowpass-filter is shared by all of a neuron's $N$ synapses\n",
    "- <b>Shared-Dendrite</b>: A single resistive-mesh is shared by all $N$ neurons' dendrites\n",
    "\n",
    "With different scaling properties:\n",
    "\n",
    "<img src=\"files/lecture10/ArchitecturesSynRAMScaling.png\" width=\"720\">\n",
    "\n",
    "- Synapse-circuit count drops from $N^2$ to $N/A$\n",
    "- RAM-word count to store weights drops from $N^2$ to $N^2/A$\n",
    "    - $A$ is the number of neurons a dendritic arbor spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Dedicated\n",
    "\n",
    "<img src=\"files/lecture10/FullyDedicated.png\" width=\"360\">\n",
    "\n",
    "Requires $N^2$ synapse circuits to fully connect $N$ neurons:\n",
    "\n",
    "- No hardware elements are shared\n",
    "- There is a one-to-one correspondence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared-Axon\n",
    "\n",
    "<img src=\"files/lecture10/SharedAxon.png\" width=\"360\">\n",
    "\n",
    "Log2($N$) wires are shared by $N$ axons:\n",
    "\n",
    "- Communicates spikes as addresses \n",
    "- Each neuron is assigned a unique addess\n",
    "- This representation is called an **address-event**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared-Synapse\n",
    "\n",
    "<img src=\"files/lecture10/SharedSynapse.png\" width=\"440\">\n",
    "\n",
    "Uses only $N$ synapse circuits to fully connect $N$ neurons:\n",
    "\n",
    "- A single circuit models each neuron’s $N$ synapses\n",
    "- All spikes destined for these synapses are routed to it\n",
    "- Requires a RAM to store weights\n",
    "\n",
    "% Do convolution in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared-Dendrite\n",
    "\n",
    "<img src=\"files/lecture10/SharedDendrite.png\" width=\"480\">\n",
    "\n",
    "Ratio of shared-synapse circuits to neurons drops below one-to-one:\n",
    "\n",
    "- A resistive mesh models exponential decay along dendrites\n",
    "- A single, shared, resistive mesh models all $N$ neurons’ dendritic trees\n",
    "- This mesh is implemented with transistors\n",
    "- Neurons receive input from neighboring shared-synapse circuits\n",
    "\n",
    "The RAM’s size and bandwidth are cut as well\n",
    "\n",
    "% Add diffusor ckt and derivation\n",
    "\n",
    "% Do convolution in space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Shared\n",
    "\n",
    "<img src=\"files/lecture10/FullyShared.png\" width=\"540\">\n",
    "\n",
    "A single, shared arithmetic unit models all elements of the neural network:\n",
    "\n",
    "- Each time a spike occurs, it updates the membrane voltages of that neuron’s targets\n",
    "- It retrieves the old value as well as the synaptic weights from RAM\n",
    "- If the new value exceeds threshold, it issues a spike\n",
    "    - Adds it to the address-event queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
